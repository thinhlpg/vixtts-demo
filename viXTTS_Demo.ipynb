{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thinhlpg/vixtts-demo/blob/dev/viXTTS_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv6wKD48of3x"
      },
      "source": [
        "# üî•üî•üî•**viXTTS Demo**üó£Ô∏èüó£Ô∏èüó£Ô∏è\n",
        "\n",
        "Demo n√†y gi√∫p b·∫°n ch·∫°y viXTTS mi·ªÖn ph√≠ tr√™n Google Colab!\n",
        "Xem th√¥ng tin m√¥ h√¨nh t·∫°i [ƒë√¢y](https://huggingface.co/capleaf/viXTTS)\n",
        "\n",
        "B·∫°n c√≥ th·ªÉ d√πng demo n√†y v·ªõi m·ª•c ƒë√≠ch:\n",
        "- ‚úÖM·ª•c ƒë√≠ch c√° nh√¢n, h·ªçc t·∫≠p, nghi√™n c·ª©u, th·ª≠ nghi·ªám\n",
        "\n",
        "B·∫°n **KH√îNG** ƒë∆∞·ª£c d√πng demo n√†y v·ªõi m·ª•c ƒë√≠ch:\n",
        "- ‚ùåM·ª•c ƒë√≠ch tr√°i ƒë·∫°o ƒë·ª©c, vi ph·∫°m ph√°p lu·∫≠t Vi·ªát Nam\n",
        "- ‚ùåT·∫°o ra n·ªôi dung g√¢y th√π gh√©t, k·ª≥ th·ªã, b·∫°o l·ª±c ho·∫∑c n·ªôi dung vi ph·∫°m b·∫£n quy·ªÅn\n",
        "- ‚ùåGi·∫£ m·∫°o danh t√≠nh ho·∫∑c g√¢y hi·ªÉu nh·∫ßm r·∫±ng n·ªôi dung ƒë∆∞·ª£c t·∫°o ra b·ªüi m·ªôt c√° nh√¢n ho·∫∑c t·ªï ch·ª©c kh√°c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kIEFgM3gnEZm"
      },
      "outputs": [],
      "source": [
        "# @title 1. ‚öôÔ∏è **C√†i ƒë·∫∑t**\n",
        "# @markdown üëàNh·∫•n n√∫t n√†y ƒë·ªÉ c√†i ƒë·∫∑t (~5 ph√∫t)\n",
        "# Change timezone to Vietnam\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/Asia/Ho_Chi_Minh /etc/localtime\n",
        "!date\n",
        "\n",
        "print(\" > C√†i ƒë·∫∑t th∆∞ vi·ªán...\")\n",
        "!rm -rf TTS/\n",
        "!git clone --branch add-vietnamese-xtts -q https://github.com/thinhlpg/TTS.git\n",
        "!pip install --use-deprecated=legacy-resolver -q -e TTS\n",
        "!pip install deepspeed -q\n",
        "!pip install -q vinorm==2.0.7\n",
        "!pip install -q cutlet\n",
        "!pip install -q unidic==1.1.0\n",
        "!pip install -q underthesea\n",
        "!pip install -q gradio==4.35\n",
        "!pip install deepfilternet==0.5.6 -q\n",
        "\n",
        "import os\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "\n",
        "os.system(\"python -m unidic download\")\n",
        "print(\" > T·∫£i m√¥ h√¨nh...\")\n",
        "snapshot_download(repo_id=\"thinhlpg/viXTTS\",\n",
        "                  repo_type=\"model\",\n",
        "                  local_dir=\"model\")\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\" > ‚úÖ C√†i ƒë·∫∑t ho√†n t·∫•t, b·∫°n h√£y ch·∫°y ti·∫øp c√°c b∆∞·ªõc ti·∫øp theo nh√©!\")\n",
        "quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oGSVcv3xuWWi"
      },
      "outputs": [],
      "source": [
        "# The inference code is adopted from https://github.com/coqui-ai/TTS/blob/dev/TTS/demos/xtts_ft_demo/xtts_demo.py\n",
        "# @title 2. ü§ó **S·ª≠ d·ª•ng**\n",
        "# @markdown üëà Nh·∫•n ƒë·ªÉ ch·∫°y.\n",
        "# @markdown N·∫øu g·∫∑p l·ªói th√¨ c≈©ng nh·∫•n n√∫t n√†y nh√©!\n",
        "\n",
        "# @markdown L·∫ßn ƒë·∫ßu ch·∫°y s·∫Ω h∆°i l√¢u, b·∫°n ch·ªù t√≠ nh√©!\n",
        "\n",
        "# @markdown K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o `/content/output`\n",
        "\n",
        "# @markdown Ch·ªçn ng√¥n ng·ªØ:\n",
        "language = \"Ti·∫øng Vi·ªát\" # @param [\"Ti·∫øng Vi·ªát\", \"Ti·∫øng Anh\",\"Ti·∫øng T√¢y Ban Nha\", \"Ti·∫øng Ph√°p\",\"Ti·∫øng ƒê·ª©c\",\"Ti·∫øng √ù\", \"Ti·∫øng B·ªì ƒê√†o Nha\", \"Ti·∫øng Ba Lan\", \"Ti·∫øng Th·ªï Nhƒ© K·ª≥\", \"Ti·∫øng Nga\", \"Ti·∫øng H√† Lan\", \"Ti·∫øng S√©c\", \"Ti·∫øng ·∫¢ R·∫≠p\", \"Ti·∫øng Trung (gi·∫£n th·ªÉ)\", \"Ti·∫øng Nh·∫≠t\", \"Ti·∫øng Hungary\", \"Ti·∫øng H√†n\", \"Ti·∫øng Hindi\"]\n",
        "# @markdown VƒÉn b·∫£n ƒë·ªÉ ƒë·ªçc. ƒê·ªô d√†i t·ªëi thi·ªÉu m·ªói c√¢u n√™n t·ª´ 10 t·ª´ ƒë·ªÉ ƒë·∫∑t k·∫øt qu·∫£ t·ªët nh·∫•t.\n",
        "input_text =\"Xin ch√†o, t√¥i l√† m·ªôt c√¥ng c·ª• c√≥ kh·∫£ nƒÉng chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh gi·ªçng n√≥i t·ª± nhi√™n, ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi nh√≥m N√≥n l√°. T√¥i c√≥ th·ªÉ h·ªï tr·ª£ ng∆∞·ªùi khi·∫øm th·ªã,  ƒë·ªçc s√°ch n√≥i, l√†m tr·ª£ l√Ω ·∫£o, review phim, l√†m waifu ƒë·ªÉ an ·ªßi b·∫°n, v√† ph·ª•c v·ª• nhi·ªÅu m·ª•c ƒë√≠ch kh√°c.\" # @param {type:\"string\"}\n",
        "# @markdown Ch·ªçn gi·ªçng m·∫´u:\n",
        "reference_audio = \"model/vi_sample.wav\" # @param [ \"model/user_sample.wav\",  \"model/vi_sample.wav\",  \"model/samples/nam-calm.wav\",  \"model/samples/nam-cham.wav\",  \"model/samples/nam-nhanh.wav\",  \"model/samples/nam-truyen-cam.wav\",  \"model/samples/nu-calm.wav\",  \"model/samples/nu-cham.wav\",  \"model/samples/nu-luu-loat.wav\",  \"model/samples/nu-nhan-nha.wav\",  \"model/samples/nu-nhe-nhang.wav\"]\n",
        "# @markdown T·ª± ƒë·ªông chu·∫©n h√≥a ch·ªØ (VD: 20/11 -> hai m∆∞∆°i th√°ng m∆∞·ªùi m·ªôt)\n",
        "normalize_text = True # @param {type:\"boolean\"}\n",
        "# @markdown In chi ti·∫øt x·ª≠ l√Ω\n",
        "verbose = True # @param {type:\"boolean\"}\n",
        "# @markdown L∆∞u t·ª´ng c√¢u th√†nh file ri√™ng l·∫ª.\n",
        "output_chunks = True # @param {type:\"boolean\"}\n",
        "\n",
        "from IPython.display import clear_output\n",
        "def cry_and_quit():\n",
        "    clear_output()\n",
        "    print(\"> L·ªói r·ªìi huhu üò≠üò≠, b·∫°n h√£y nh·∫•n ch·∫°y l·∫°i ph·∫ßn n√†y nh√©!\")\n",
        "    quit()\n",
        "\n",
        "import os\n",
        "import string\n",
        "import unicodedata\n",
        "from datetime import datetime\n",
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "from underthesea import sent_tokenize\n",
        "from unidecode import unidecode\n",
        "\n",
        "try:\n",
        "    from vinorm import TTSnorm\n",
        "    from TTS.tts.configs.xtts_config import XttsConfig\n",
        "    from TTS.tts.models.xtts import Xtts\n",
        "except:\n",
        "    cry_and_quit()\n",
        "\n",
        "# Load model\n",
        "def clear_gpu_cache():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "def load_model(xtts_checkpoint, xtts_config, xtts_vocab):\n",
        "    clear_gpu_cache()\n",
        "    if not xtts_checkpoint or not xtts_config or not xtts_vocab:\n",
        "        return \"You need to run the previous steps or manually set the `XTTS checkpoint path`, `XTTS config path`, and `XTTS vocab path` fields !!\"\n",
        "    config = XttsConfig()\n",
        "    config.load_json(xtts_config)\n",
        "    XTTS_MODEL = Xtts.init_from_config(config)\n",
        "    print(\"Loading XTTS model! \")\n",
        "    XTTS_MODEL.load_checkpoint(config,\n",
        "                               checkpoint_path=xtts_checkpoint,\n",
        "                               vocab_path=xtts_vocab,\n",
        "                               use_deepspeed=True)\n",
        "    if torch.cuda.is_available():\n",
        "        XTTS_MODEL.cuda()\n",
        "\n",
        "    print(\"Model Loaded!\")\n",
        "    return XTTS_MODEL\n",
        "\n",
        "\n",
        "def get_file_name(text, max_char=50):\n",
        "    filename = text[:max_char]\n",
        "    filename = filename.lower()\n",
        "    filename = filename.replace(\" \", \"_\")\n",
        "    filename = filename.translate(str.maketrans(\"\", \"\", string.punctuation.replace(\"_\", \"\")))\n",
        "    filename = unidecode(filename)\n",
        "    current_datetime = datetime.now().strftime(\"%m%d%H%M%S\")\n",
        "    filename = f\"{current_datetime}_{filename}\"\n",
        "    return filename\n",
        "\n",
        "\n",
        "def calculate_keep_len(text, lang):\n",
        "    if lang in [\"ja\", \"zh-cn\"]:\n",
        "        return -1\n",
        "\n",
        "    word_count = len(text.split())\n",
        "    num_punct = (\n",
        "        text.count(\".\")\n",
        "        + text.count(\"!\")\n",
        "        + text.count(\"?\")\n",
        "        + text.count(\",\")\n",
        "    )\n",
        "\n",
        "    if word_count < 5:\n",
        "        return 15000 * word_count + 2000 * num_punct\n",
        "    elif word_count < 10:\n",
        "        return 13000 * word_count + 2000 * num_punct\n",
        "    return -1\n",
        "\n",
        "\n",
        "def normalize_vietnamese_text(text):\n",
        "    text = (\n",
        "        TTSnorm(text, unknown=False, lower=False, rule=True)\n",
        "        .replace(\"..\", \".\")\n",
        "        .replace(\"!.\", \"!\")\n",
        "        .replace(\"?.\", \"?\")\n",
        "        .replace(\" .\", \".\")\n",
        "        .replace(\" ,\", \",\")\n",
        "        .replace('\"', \"\")\n",
        "        .replace(\"'\", \"\")\n",
        "        .replace(\"AI\", \"√Çy Ai\")\n",
        "        .replace(\"A.I\", \"√Çy Ai\")\n",
        "    )\n",
        "    return text\n",
        "\n",
        "\n",
        "def run_tts(XTTS_MODEL, lang, tts_text, speaker_audio_file,\n",
        "            normalize_text= True,\n",
        "            verbose=False,\n",
        "            output_chunks=False):\n",
        "    \"\"\"\n",
        "    Run text-to-speech (TTS) synthesis using the provided XTTS_MODEL.\n",
        "\n",
        "    Args:\n",
        "        XTTS_MODEL: A pre-trained TTS model.\n",
        "        lang (str): The language of the input text.\n",
        "        tts_text (str): The text to be synthesized into speech.\n",
        "        speaker_audio_file (str): Path to the audio file of the speaker to condition the synthesis on.\n",
        "        normalize_text (bool, optional): Whether to normalize the input text. Defaults to True.\n",
        "        verbose (bool, optional): Whether to print verbose information. Defaults to False.\n",
        "        output_chunks (bool, optional): Whether to save synthesized speech chunks separately. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the synthesized audio file.\n",
        "    \"\"\"\n",
        "\n",
        "    if XTTS_MODEL is None or not speaker_audio_file:\n",
        "        return \"You need to run the previous step to load the model !!\", None, None\n",
        "\n",
        "    output_dir = \"./output\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    gpt_cond_latent, speaker_embedding = XTTS_MODEL.get_conditioning_latents(\n",
        "        audio_path=speaker_audio_file,\n",
        "        gpt_cond_len=XTTS_MODEL.config.gpt_cond_len,\n",
        "        max_ref_length=XTTS_MODEL.config.max_ref_len,\n",
        "        sound_norm_refs=XTTS_MODEL.config.sound_norm_refs,\n",
        "    )\n",
        "\n",
        "    if normalize_text and lang == \"vi\":\n",
        "        # Bug on google colab\n",
        "        try:\n",
        "            tts_text = normalize_vietnamese_text(tts_text)\n",
        "        except:\n",
        "            cry_and_quit()\n",
        "\n",
        "    if lang in [\"ja\", \"zh-cn\"]:\n",
        "        tts_texts = tts_text.split(\"„ÄÇ\")\n",
        "    else:\n",
        "        tts_texts = sent_tokenize(tts_text)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Text for TTS:\")\n",
        "        pprint(tts_texts)\n",
        "\n",
        "    wav_chunks = []\n",
        "    for text in tqdm(tts_texts):\n",
        "        if text.strip() == \"\":\n",
        "            continue\n",
        "\n",
        "        wav_chunk = XTTS_MODEL.inference(\n",
        "            text=text,\n",
        "            language=lang,\n",
        "            gpt_cond_latent=gpt_cond_latent,\n",
        "            speaker_embedding=speaker_embedding,\n",
        "            temperature=0.3,\n",
        "            length_penalty=1.0,\n",
        "            repetition_penalty=10.0,\n",
        "            top_k=30,\n",
        "            top_p=0.85,\n",
        "        )\n",
        "\n",
        "        # Quick hack for short sentences\n",
        "        keep_len = calculate_keep_len(text, lang)\n",
        "        wav_chunk[\"wav\"] = torch.tensor(wav_chunk[\"wav\"][:keep_len])\n",
        "\n",
        "        if output_chunks:\n",
        "            out_path = os.path.join(output_dir, f\"{get_file_name(text)}.wav\")\n",
        "            torchaudio.save(out_path, wav_chunk[\"wav\"].unsqueeze(0), 24000)\n",
        "            if verbose:\n",
        "                print(f\"Saved chunk to {out_path}\")\n",
        "\n",
        "        wav_chunks.append(wav_chunk[\"wav\"])\n",
        "\n",
        "    out_wav = torch.cat(wav_chunks, dim=0).unsqueeze(0)\n",
        "    out_path = os.path.join(output_dir, f\"{get_file_name(tts_text)}.wav\")\n",
        "    torchaudio.save(out_path, out_wav, 24000)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Saved final file to {out_path}\")\n",
        "\n",
        "    return out_path\n",
        "\n",
        "\n",
        "language_code_map = {\n",
        "    \"Ti·∫øng Vi·ªát\": \"vi\",\n",
        "    \"Ti·∫øng Anh\": \"en\",\n",
        "    \"Ti·∫øng T√¢y Ban Nha\": \"es\",\n",
        "    \"Ti·∫øng Ph√°p\": \"fr\",\n",
        "    \"Ti·∫øng ƒê·ª©c\": \"de\",\n",
        "    \"Ti·∫øng √ù\": \"it\",\n",
        "    \"Ti·∫øng B·ªì ƒê√†o Nha\": \"pt\",\n",
        "    \"Ti·∫øng Ba Lan\": \"pl\",\n",
        "    \"Ti·∫øng Th·ªï Nhƒ© K·ª≥\": \"tr\",\n",
        "    \"Ti·∫øng Nga\": \"ru\",\n",
        "    \"Ti·∫øng H√† Lan\": \"nl\",\n",
        "    \"Ti·∫øng S√©c\": \"cs\",\n",
        "    \"Ti·∫øng ·∫¢ R·∫≠p\": \"ar\",\n",
        "    \"Ti·∫øng Trung (gi·∫£n th·ªÉ)\": \"zh-cn\",\n",
        "    \"Ti·∫øng Nh·∫≠t\": \"ja\",\n",
        "    \"Ti·∫øng Hungary\": \"hu\",\n",
        "    \"Ti·∫øng H√†n\": \"ko\",\n",
        "    \"Ti·∫øng Hindi\": \"hi\"\n",
        "}\n",
        "\n",
        "print(\"> ƒêang n·∫°p m√¥ h√¨nh...\")\n",
        "try:\n",
        "    if not vixtts_model:\n",
        "        vixtts_model = load_model(xtts_checkpoint=\"model/model.pth\",\n",
        "                                xtts_config=\"model/config.json\",\n",
        "                                xtts_vocab=\"model/vocab.json\")\n",
        "except:\n",
        "    vixtts_model = load_model(xtts_checkpoint=\"model/model.pth\",\n",
        "                                xtts_config=\"model/config.json\",\n",
        "                                xtts_vocab=\"model/vocab.json\")\n",
        "clear_output()\n",
        "print(\"> ƒê√£ n·∫°p m√¥ h√¨nh\")\n",
        "\n",
        "if not os.path.exists(reference_audio):\n",
        "    print(\"‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏èB·∫°n ch∆∞a t·∫£i file √¢m thanh l√™n. H√£y ch·ªçn gi·ªçng kh√°c, ho·∫∑c t·∫£i file c·ªßa b·∫°n l√™n ·ªü b√™n d∆∞·ªõi.‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\")\n",
        "    audio_file=\"/content/model/vi_sample.wav\"\n",
        "else:\n",
        "    audio_file = run_tts(vixtts_model,\n",
        "            lang=language_code_map[language],\n",
        "            tts_text=input_text,\n",
        "            speaker_audio_file=reference_audio,\n",
        "            normalize_text=normalize_text,\n",
        "            verbose=verbose,\n",
        "            output_chunks=output_chunks,)\n",
        "\n",
        "from IPython.display import Audio\n",
        "Audio(audio_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "C7Bm9c2iTmpQ"
      },
      "outputs": [],
      "source": [
        "# @title üé§ **T·∫£i file √¢m thanh c·ªßa b·∫°n l√™n**\n",
        "# @markdown ƒê·ªÉ ƒë·∫°t ch·∫•t l∆∞·ª£ng t·ªët nh·∫•t, h√£y tham kh·∫£o file '/content/model/vi_sample.wav'\n",
        "# @\n",
        "import os\n",
        "import locale\n",
        "from google.colab import files\n",
        "\n",
        "denoise = True # @param {type:\"boolean\"}\n",
        "\n",
        "# Upload the audio file\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    # Convert the audio file to WAV format using ffmpeg\n",
        "    uploaded_dir = os.path.dirname(filename)\n",
        "    if denoise:\n",
        "        !deepFilter \"{filename}\"\n",
        "        !ffmpeg -i \"{filename.replace('.wav', '_DeepFilterNet3.wav')}\" -ac 1 -ar 22050 -vn /content/model/user_sample.wav -y -hide_banner -loglevel error\n",
        "        os.remove(filename.replace('.wav', '_DeepFilterNet3.wav'))\n",
        "    else:\n",
        "        !ffmpeg -i \"{filename}\" -ac 1 -ar 22050 -vn /content/model/user_sample.wav -y -hide_banner -loglevel error\n",
        "        os.remove(filename)\n",
        "    break\n",
        "\n",
        "from IPython.display import Audio, clear_output\n",
        "clear_output()\n",
        "print(\"> ƒê√£ t·∫£i file √¢m thanh l√™n\")\n",
        "Audio(\"/content/model/user_sample.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6sC6v6pNQVt5"
      },
      "outputs": [],
      "source": [
        "# @title ‚è¨ **L∆∞u k·∫øt qu·∫£ v√†o Drive**\n",
        "# @markdown Ch·∫°y ph·∫ßn n√†y ƒë·ªÉ l∆∞u k·∫øt qu·∫£ v√†o Google Drive c·ªßa b·∫°n\n",
        "# @markdown `/content/drive/MyDrive/vixtts-output`\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save the output folder in \"vixtts-output\" in Google Drive, without overwriting existing files\n",
        "!cp -n -r /content/output/* /content/drive/MyDrive/vixtts-output\n",
        "print(\"> ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o Google Drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7-X619YbX0n-"
      },
      "outputs": [],
      "source": [
        "# @title ‚ö†Ô∏è **D·ªçn k·∫øt qu·∫£**\n",
        "# @markdown Ch·∫°y ph·∫ßn n√†y ƒë·ªÉ x√≥a to√†n b·ªô file trong `/content/output`\n",
        "import shutil\n",
        "shutil.rmtree('/content/output')\n",
        "print(\"ƒê√£ x√≥a to√†n b·ªô file trong /content/output\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üì¥ **T·∫Øt Demo**\n",
        "# @markdown Khi ch·∫°y xong th√¨ b·∫°n h√£y t·∫Øt demo ƒë·ªÉ ti·∫øt ki·ªám GPU nh√©!\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cvzEJ8c_PkRb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyN7+AM4TCVxzIzD/jayBMlv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}